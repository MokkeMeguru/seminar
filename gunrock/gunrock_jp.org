#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+options: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+options: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+options: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+title: gunrock_jp
#+date: <2019-03-17 Sun>
#+author: MokkeMeguru
#+email: meguru.mokke@gmail.com
#+language: ja
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 25.2.2 (Org mode 9.2.2)
* 概要
Gunrok は オープンドメインな対話システムで、ユーザに寄り添う形にデザインされた social bot です。
我々はより人間らしい bot を目指すため、大規模なユーザの対話データを繰り返しこの bot に与えました。例えば、このシステムは 2018 年度に行われた Amazon Alexa Prize の準決勝期間中に 4万回を超える会話経験を積みました。
内部については、話題のhttps://www.youtube.com/watch?v=yTuCWE99rcY転換や質疑応答といったユーザの様々な振る舞いに対して、文脈に応じて階層的な会話を行うことのできる対話管理システムを適用しました。これに加え、我々は頑強な 3 ステップの自然言語理解のためのモジュール(NLU moduleRTX3900)を設計しました。この中の例としては、文の細分化や自動音声認識エラー修正システムを挙げることができます。更に、我々は bot が人間らしい振る舞いをすることができるように、韻律音声合成を行いました。
これらの多くの努力の結果として、この bot は 10月14日に行われたユーザによる 1-5 点評価のアンケート調査によって 3.62 点の評価を得ることができました。加えてこの調査では、平均 22.14 ターン、時間にして 5分 22秒の連続会話を達成することができました。
* 導入
対話システムの研究における一つの重要な課題として、より多くのユーザによってそのシステムが訓練・テストされなければならないことを挙げることができる。これに対処するために、ほとんどの研究者は、クラウドソーシングされたプラットフォーム上で、コストをかけることで彼らのシステムを訓練・評価していました。しかし、そうやって訓練・評価されたシステムは実際の製品に適用した際に不安定な結果を招く可能性がありました。我々は45日の評価期間で、一日に500対話以上のデータを入手し、最終的に開発期間全体(~ 8月 14日)では 487,314 対話を入手することができました。例えば Amazon Echo といった Alexa が搭載されたどのようなマシンにおいても、アメリカ国内ならば我々のシステムを試すことができました。我々のシステムは多様なユーザの大規模なアクセスに対処する必要がありました。

人間は人間同士のコミュニケーションパターンに慣れているため、ほとんどのユーザは人間対人間のコミュニケーションが行えることをシステムに求めると我々は考えています。例えば、 Microsoft Cortana(パーソナルアシスタントの一種) はソーシャルコンテンツに対処することができないということが知られていますが、ユーザの発言の30％はソーシャルコンテンツを求めています。そのため、対話システムの性能を向上させる有効打の一つとして、人間のコミュニケーションを模倣させることが考えられます。そこで我々は特定の人気のある話題について深く会話することができるという能力を持ち、多様な社会的トピックを網羅することができる、人間対人間の自然な対話を模倣する オープンドメインな social bot である Gunrock を提案しました。これによって我々は、オープンドメインな発話理解・対話管理・そして自然言語生成の分野に多くの貢献をすることができました。

このオープンドメインな発話理解には2つの大きな課題がありました。それは、1. ASR(自動音声認識) エラーと 2. 実体(エンティティ)の曖昧さです。我々はこの問題に対して、新たに3段階の自然言語理解(NLU)のパイプラインを設計しました。というのも、ユーザは一度に複数の文を繋げて話すことができるものの、ASRはそれを一つの文として認識してしまい複数の文に分割することができません。我々のNLUは、これに対処するために、まずASRから入ってくる原文を複数の小さなセグメントに分割します。そしてそれらの小さなセグメントに様々なNLPの技術を用いて固有表現(named entity)・対話の意図・感情についての情報を抽出します。最後に、相互参照・ASRエラー・エンティティの曖昧さの解決のために、文脈情報や音声情報を活用します。

更に我々は、ユーザ間の様々な異なる会話に対処するための、階層的な積立形式の（stack-based) 対話管理システムを設計しました。この対話管理システムは第一に、NLUから得られる情報を用いてユーザのリクエストを映画やスポーツといったトピックに振り分ける高レベルの決定機関を持ちます。そして振り分けられたトピックに対応する固有のトピック対話モジュールが呼び出されます。各トピック対話モジュールでは、より詳細で包括的な会話にユーザを参加させるために役立つ定義済みの会話フローが組み込まれています。様々なユーザの行動に対応し、会話の一貫性を保つために、システムはこのフローに出入りして、いつでも事実に関する/個人的な質問に答えることができます。これに加えて異なるドメイン固有のトピック対話モジュール間に作成されたトンネルを使用して、ユーザの意図的な話題の切り替えに対応できるようにします。

システムの発話生成については、そｓの内容と同じ位に重要な要素です。より人間的な相互作用を形成するために、Amazonの音声合成マークアップ言語 (SSML) を用いて韻律効果のライブラリを作成しました。我々は、ユーザからのインタビューから、韻律効果や間投詞がより自然であるように彼らから求められていることがわかりました。
* 関連研究
タスク指向な対話システムや、オープンドメインな対話システムは広く研究されています。前者は特にレストランの予約といった場面に研究されています。オープンドメインなものでは、Alice のような古代のチャットボットが Turing Test をクリアするために作成されていたのに対して、Amazon Alexa や Google Assistant のような最近の対話システムはユーザとの短いターンの対話や、質疑応答の対話に対して焦点を当てています。これらに対して、social chatbot は感情的なサポートを含めた深いコミュニケーションスキルが要求されます。Gunrock は タスク指向・オープンドメインの両方の分野の SOTA (state-of-the-art) の技術を利用し、より柔軟にユーザとの会話ができるようになっています。

多くの神経モデル（naural models）や強化学習モデルが、言語理解や文生成のために提案されています。 Cornell Movie Dialogs や Reddit といった大規模データセットに支えられ、それらの end-to-end なアプローチのモデルは対話の性能を向上させています。しかしこれらの手法は対話の一貫性がないことや多様性が得られにくいというような問題を抱えています。

この問題の解決策として、ルールベースと end-to-end のモデルを組み合わせるアプローチを用いたいくつかの研究が存在しています。他の関連研究としては、個々の小さな技術と知識グラフを活用しています。2017年度の Amazon Alexa Prize の優勝システムである Sounding Board はこの関連研究を活かしていると言えます。このアプローチはユーザエクスペリエンスを向上させ、対話時間を伸ばすことができることがわかったが、その一方で、この手法には新しい話題に対して柔軟な対応をすることができず、ユーザからの意見に基づく要求をしっかりと処理することができません。（知識グラフから対話を生成するという都合上、要求や意見に対して弱い、という意味のようです）

我々のシステムは異なるドメインのデータセットを連結させる利点を最大限に活かし、トピック対話モジュール間をシームレスに移行するトンネルを作成しました。我々は自然言語理解(natural language understanding NLU) と自然言語生成 (natural language generation NLG) のためにユーザから収集したデータに加え、先述のデータセットを利用してモデルを訓練しました。この新しいコンセプトは Amazon Alexa Priza で優秀な成績を残すことに非常に貢献したと言えるでしょう。
* システムの構成
我々は Amazon Conversational Bot Toolkit を活用してシステムアーキテクチャを構築しました。この Toolkit は、開発者がユーザフレンドリーな bot を構築することに集中できるよう、簡単にスケールできるフレームワークを提供します。そのイベント駆動ベースなシステムは AWS Lambda function 上で実装され、ユーザが bot にリクエストを送信されたときに呼び出されます。この bot のインフラとして、ユーザデータと対話の状態データの両方を DynamoDB に格納するための 状態管理インターフェースも挙げることができます。

我々は更に、Redis や Amazon が新たに提供したグラフデータベースである Neptune を内部の知識グラフを構築するために活用しています。
** システムの概要
   Figure 1 はこの social bot のシステムのフレームワークを示しています。Amazon は ASR モデルを通してユーザの発話をテキストとする部分と、Amazon Alexa の Text-To-Speech (TTS) を用いてテキストを発話に変換する部分を提供しています。我々のシステムの重点はテキストの入出力にあります。
待ち時間が長くなる可能性があるため、ユーザからの信頼性が低い・劣悪な・不完全な入力といった一部のシナリオについては、いくつかのモジュールを使用して応答文を生成します。例えば、もし ASR の結果が信頼におけるものではないと評価されたならば、ユーザに同じことを繰り返してもらうか、またはより明確に説明してもらえるよう求めるプロンプトを生成します。

ASRを通過した後、ユーザの入力は複数の NLU のコンポーネントに通されます。例えばそのコンポーネントは、 Amazon Toolkit のサービスや、対話行為の検出器(dialog act detector)といったものです。この内容については後に紹介します。

対面及びオンラインのいずれの場合にしても、人々は乱暴なな文脈を含む対話を行うことがあります。我々は Amazon Offensive Speech Classifier Toolkit を用いてそのような内容を排除できるようにしています。（おそらくTwitter上で活動していた対話AIが悲惨な（不適切な教育を受けてしまった）ことを考慮した対処でしょう）また、もし現在話している内容が不適切な兆候を示している場合には、その話題が不適切であることをユーザに知らせるとともに、別の話題を提供します。

Figure 1 では 12 のコンポーネントが NLU に含まれていることがわかります。待ち時間と依存関係の間のトレードオフとのバランスを取るために、このボットに組み込まれている自然言語処理のパイプラインとスレッドプール設計を利用します。NLU のパイプラインは3つのステップで構成されています。第一のステップでは、入力は複数の文に分割されます。次のステップでは、名詞句が検出されます。最後のステップでは、抽出された名詞句を元に Figure 1 の NLU の下部に示されるような詳細なコンポーネントで分類します。

対話管理システムでは、意図分類器（Intent Classifier）が異なるユーザの意図を対応するトピック対話モジュールに向けるために使用されます。それらは映画やスポーツ、動物といったいくつかの特定の話題をカバーしています。それぞれの対話モジュールは独自の対話フローを持っており、ユーザはその流れに沿って柔軟に深く会話を行うことができます。すべての対話モジュールは、Amazon の EVI サービス や back-story を利用して、例えば「あなたの好きな色は何ですか？」といった bot のペルソナに関連した質問に答えたり、現実の質問（例えば「今の米国大統領はだれ？」）に答えることができます。加えて、Amazon EC2 インスタンスを用いることで、複数のデータソースや、蓄積されている知識ベースからデータを収集します。文脈情報とともにNLUから得られたすべての情報は、応答を生成する役割を担う NLG の適切なモジュールを選択するために用いられます。

NLGシステムは、システムの応答テンプレートを一元管理するためにテンプレートマネージャ（Template Manager）を利用します。回答の健全性を確実にするために、回答内容を精査するための機構（Profanity Check）も含まれます。元のトピック対話モジュールの状態を更新するためのポストプロセッサ（Post Processor）もNLGに含まれています。最後に、Amazon SSMLを用いて生成文の韻律を調整します（Prosody）。
** Automatic Speech Recognition
   ユーザの入力はNLUに入る前に、ASRのエラーを処理するため、ASRから得られる全体的な信頼スコアとそれぞれの単語についての信頼スコアを元に前処理されます。本システムでは、信頼スコアに応じて以下の3種類のASRエラー応答を定義しました。
   1. Critical Range
      全体的な信頼スコアやそれぞれの単語についての信頼スコアが0.1を下回った場合、本システムは全体のパイプラインを一旦停止させ、ユーザに入力を繰り返すか別の言葉で表現するかを促します。
   2. Warning range
      全体的な信頼スコアやそれぞれの単語についての信頼スコアが0.4未満0.1以上であった場合、本システムはASRの修正を行うシステムへ入力を送ります。
   3. Safe range
      上のいずれでもなければ、入力をそのままASRによって得られた結果としてNLUへ送ります。

   　また、ユーザの予想外な入力（例えば苦情や不完全な文）に対しても処理を定義しています。一般にこのような状況では、単に情報を提供するだけでは、ユーザエクスペリエンスが低下する可能性があることが知られています。そのため、ASRでの前処理として、それらの異常な入力を検出し、それらを明確化するためのユーザへの応答を行う機能を作成しました。
** NLU (自然言語理解)
   Alexa Skills Kit(ASK) はNLUのためのトピック分類や、感情分類、不適切文検知、そしてNERの機能を提供しています。我々はこれに、ユーザからの入力を分割するための文分割モデル(sentence segmemtation model) を加えました。これによってユーザからの入力を意味単位に分け、各意味単位に対して他のNLUの機能を適用していきます。
*** 文分割(Sentence Segmentation)
    本システムは対話をより面白くするために、対話フローに束縛されないオープンドメインの質疑応答ができるよう構成されています。この質疑応答によってユーザがより対話を行うようになることが見込めますが、代償としてユーザの入力文がより複雑になる可能性があります。我々は文分割を行うための Seq2Seq model 型の(end-to-endな)モデルを Cornel Movie-Quotes Corpus で訓練しました。この Corpus には 304,713 対話と、ラベル付された検証データが 23,760 発話が含まれています。このデータは文の区切りに特別なトークンを付与するという前処理が行われています。このモデルは単語埋め込みとして Common Crawl のデータを元にした（このデータには200万単語が含まれています）300次元の fastText を用いています。Seq2Seq モデルとしては、2層の双方向LSTMをエンコーダ、2層のRNNをデコーダとして採用しており、global attention機構を用いています(恐らくこれは Luong Attention モデルの改変です)。単語埋め込みから同様の単語が生成されたとき、その特別なトークンを除いてその出力単語を入力単語と同じ単語になるように修正します（同じ単語を用いる方が文が繋がりやすいという予測からか？）。
    このモデルは30エポック訓練され、結果として検証データ 220 発話に対して 95.95% の精度(accuracy)を達成しました。これは事前訓練された言語モデル(?)よりも優れた精度を示しています。ここで文分割の例を示すと、``Alexa that is cool what do you think of the Avengers'' は ``Alexa <BRK> that is cool <BRK> what do you think of the Avengers <BRK>'' となります。
    さらにこのような文中の切れ目を効率的に検出するために、ユーザデータにラベル付をすることやASRから得られた結果を用いてユーザの発話記録に注釈をつけ各単語間の相対的な空白時間を利用しました。具体的には以下の確率を最大化しました。
    \begin{eqnarray}
    p(x_i|x_1, \dots , x_{i-1}, \cfrac{t_i}{\bar{t}})
    \end{eqnarray}
    ここで、$x_i$ とは入力された単語あるいは分割のシグナル (<BRK>) であり、$t_i$ は ASR から得られた $x_i$ と $x_{i-1}$ との間に起こる時間差、$\bar{t}$ はその平均です。
    この手法の課題点に、固有表現抽出と不完全な入力文への対応（恐らく日本語にある省略など？）があります。今後これらの問題については取り組んでいく予定です。
*** 名詞句の抽出(Noun Phrase Extraction)
    Stanford CoreNLP のパーサ (Stanford CoreNLP constituency parser) を用いることで、入力文を名詞句やローカルな名詞句(解析木の葉のレベルなもの)を抽出します。いくつかのストップワードに関してはフィルタリングを行い、残ったものを他のNLUのモジュールなどのキーワードとみなしました。
    将来的には、複数の名詞句の従属関係を解析し主語・目的語などを識別できるようにします。
*** 表現抽出（Entity Recognition）
    Stanford CoreNLP や spaCy といった NER を処理できるツールは、大文字・小文字といった単語の性質に強く依存していると考えており、音声認識から文字を書き起こす我々のシステムに対しては適用が難しいと考えています。加えてそれらのツールは、教師データに与えられていないような表現を抽出することが難しいです。このため、より多くのデータを用いて表現抽出をできるように、並行して以下の3つの表現抽出のためのプログラムを用いました。
    1. Google Knowledge Graph
       Google Knowledge Graph を利用して、名詞句について検索を行い、それに対するラベル・信頼度を生成し、その結果を Redis にキャッシュします。また、説明を我々の作成したモジュールにマッピングします。例えば、名詞句「tomb raider」は 「video game series」 というラベルが高い信頼度で付属しているので、これを game モジュールに対してマッピングします。さらに、名詞句を明確にするために複数のラベルを抽出します。（例えば「tomb raider」は movie ラベルも含んでいると言えます。）またその名詞句に信頼度が高いラベルが複数ある場合には、追加情報として文脈が考慮されるようになります。
    2. Microsoft Concept Graph
       また名詞句を分類するために、Microsoft Concept Graph も用いました。Google Knowledge Graph に比べて、より一般的なカテゴリが提供され、モジュールに分類する際に効率良く行うことができます。
    3. ASR Correction
       表現獲得のためにグラフを用いるというアイデアとは異なり、ASR 修正システムも用いました。詳細は後述されます。

    これらに加えて、表現抽出のために文脈も考慮に入れました。例えば、システムが提案した映画関連の質問を通すことによって（文脈の獲得）Table 1 に挙げる映画の話題で登場した「her」を検出することができます。後述されるように、これらから得られた情報は意図分類(intent classification) のために結合されます。
*** Coreference Resolution
    Stanford CoreNLP と NeuralCoref を用いた SOTA なモジュールは、非会話データを元にして訓練されていました。そのため会話での照応解消(anaphora resolution)（恐らく it, one などの意味的置換？）ではうまくいきませんでした。集められたデータを解析していくに連れ、我々は相互参照を受ける "more" や "one" といった単語をラベル付けしました。我々はこれらの単語をユーザの発話とシステムの応答を元に置換します。具体的には入力からの名詞句と、システムからの応答から得られる詳細な説明を含むNERの結果を、そのユーザの属性として保存します。そしてユーザが参照している内容に応じて、対応する相互参照の内容を提供します。
    将来的にはより多くの文脈を考慮できるようにし、我々は選択された単語リストを超えることができ、かつより明確に定義された優先順位で認識するようなモデルを訓練したいです。
*** ASR Correction
    ASR エラーは NLU の精度に大きな影響を与えることがわかっています。ASKは各単語の信頼度スコアと言語モデルから生成された信頼度スコアの両方を組み込むことで、全体的な ASR の信頼度スコアを算出します。全体のスコアは発話全体が正しく認識されている確率を示します。しかし誤検知（信頼度が低くなりASRエラーを発生してしまうこと）の可能性が2つあります。1つ目は言及されている単語が訓練データに頻繁に見られない際に、その単語の重みが低くなってしまうことです。もう一つは、ASRを用いることでも回避できない同音語による誤検知です。
    我々はユーザと knowledge base を用いて言及された名詞句 (但し頻度の高い単語を無視するものとする)を比較するため、double metaphone algorithm を用いました。knowledge base は文脈やドメイン（例えばスポーツのジャンルやゲーム名）情報を保存しています。詳しく言うと、値として単語をキーとして各単語のための double metaphone アルゴリズムによって得られる 1次コードと 2次コードを保存しました。更に観測に基づいて、特定のパターンを持つ単語に 3次コードを適用し、保存しました(例えば"jalapeno"という単語は、コードとして "HLPN", "JLPN" そして "ALPN" を持っています)。もしASRから得られる全体の信頼度が閾値(0.4 にセットされています)から低い場合には、名詞句の metaphone コードを knowledge base のそれと一致するような候補を調べ選択肢として提案します（妥当性のある文に書き換える？）。例えば、"obscure holuidays" についての話題が話されている際に、ユーザから "let's talk about secure holiday" という入力を受け取ったものとします。ここで "secure holiday" の １次コードは "SKRLT" であり、 "obscure holidays" の 1次コードは "APSKRLTS" です。ASRが発音の始まりと終わりをうまく認識できないことがあるため、この手法は比較的信頼度を高めることができると考えられます。別の例としては、スポーツについての話題の際に、"let's talk about he sport high ally" という入力がASRからあったとして、 high ally は一時コードして "jai alai" が knowledge base の "sports list" から提案されます。
*** Dialog Act Prediction
    NLU から得られたそれぞれの分割された文 (segmented sentence)は Dialog Act に関連付けられます。Dialog act は意見や主張といった会話の文脈を与えられた対話における機能です。この機能を予測するために、LSTMとCNN モデルを訓練しました。前者には 埋め込み次元300 の fastText 用いた単語埋め込みを用い、隠れ層の次元 500 の ２層の双方向LSTMモデルを採用しました。後者には同じく単語埋め込みを用いたカーネルサイズ３の２層CNNモデルを用いました。対話ログに十分なアノテーションこそないものの、我々は Switchboard Dialog Act Corpus (SWDA) が有用ではないかと考えました。 SWDA データセットはオープンドメインな電話対話の 205,000 発話を収録しており、60の dialog act のタグが付与されています。発話が順番にやってくる本システムのユースケースに対応するため、データを 156,809 発話に前処理し（carefully と強調しているので恐らく手作業？）、dialog act のタグを 40 まで減らしました。最も多いタグは statemenet-non-opinion や statement-opinion 、そして yes-no-questions でした。2つのモデルはこの処理されたデータセットに対して訓練されました。
    検証データに対する accuracy は LSTMモデルが 85.60% を達成したのに対して、CNNモデルは 85.25% を達成しました。更には、データセットとは無関係のデータ（143 のランダムに選ばれた独立な発話データ）で検証を行ったところ、LSTMモデルはCNNモデルよりも良い結果である 83.77% を達成しました。尚実際には、求めた dialog act のタグの種類は 19 にまでまとめられ、信頼度と共に求められます。例えば、 "awesome i like books why do you think the great gatsby is a great novel" は "awesome [appreciation] | i like books [opinion] | why do you think the great gatsby is great novel [open question]" という形に分割され (sentence segment の機能より)タグ付け(dialog act prediction)が行われます。誤りの過半数は statement/opinion の曖昧さによるもの（例えば "I like the movie Avengers"）、不完全な文が主な原因となっていると考えています。
    この Dialog act は文脈情報に依存しており、最適な結果を得るにはその前の対話内容及び現在の対話文（ segmented sentence）単位からの条件付き確率を最大化する必要があります。我々はこのモデルを事前訓練された埋め込みモデルであるELMoや再帰的な畳込みモデルを用いることで再帰化しようと考え、現在実験、評価を行っています。将来的には、dialog act prediction と sentence segmentation の両方を学習するような (multi-task learning) モデルを構築したいと考えています。更には、Dialog act prediction モデルと言語モデルを組み合わせて、発話が解釈不能であるかどうか、及びその応答がユーザに割り込み可能であるか（応答として適切であるかどうか）を判定したいと考えています。
*** Topic Expansion
    本システムでは抽出された名詞句の展開を行うための knowledge graph として ConceptNet を用いました。本システムの実装の初期段階に多く寄せられた意見として、システムがトピック（話題）を突然切り替えてしまったというものがありました。システム内のデータベースに保存できるようユーザに情報をより多く共有してもらう学習プロセスとは別に、本システムは同様のトピック（話題）について話すことができるようになりました。例えばユーザが車についての話題を話したい際に、本システムはConceptNetから様々なタイプの車（例えば Volvo）のリストを取得します。そのためユーザが好きな車の種類を尋ねとして、Dialog act によって分類された (e.g. story や opinion、asking a question) 入力文にコメントをつけた後、knowledge base からVolvoから拡張された情報を得ることができます。
** Dialog Management
   本システムはユーザの対話を扱うための2階層の対話管理を行います。上層ではNLUから得られる出力を活用して、それぞれのユーザの発話に対して最も適当な topic dialog module を選択します。下層では該当する応答を生成する dialog module を活性化させます。
*** High-Level System Dialog Management
    本システムは、まずNLU出力に基づいてユーザの意図(opinion statement etc.)を識別し、次に各サブモジュールのフィードバックと組み合わせて、どのサブモジュールがユーザの発話を処理すべきであるかを判定します。
    - Intent Classifier    
      本システムはCommon Alexa Prize Chats dataset (CAPC) に基づき、ユーザの意思を3段階に分けました。これは 2017 年度の Alexa Prize Competiton にて収集された、匿名の人-AI の対話データセットです。
      我々はまず、social chat domain system のリクエストを処理します。このリクエストには例えば、"play music" "set the temparature" "turn on the lights" といった命令が含まれます。これらの我々の開発する bot 内では解決できないリクエストは、ユーザにAlaxa の組み込みの機能を利用するよう促すため、 social mode（本システムの対話パート） を終了する方法を提示します。
      次に、ユーザの入力から話題を特定します。本システムは正規表現と Google Knowledge Graph, Microsoft Concept Graph, そして Amazon Alexa Prize Topic Classifier を組み合わせて話題を特定します。また、収集したヒューリスティックなデータと、対話データに基づいて、これらの3つの信頼性のしきい値を調節します。もし一つの発話に対して複数の話題が推測された場合で、それらのうちの一つが以前選択されたものと同じ話題であった場合には、その話題について話されているものと判定します。そうでなければ、信頼度の最も高い話題を選択します。
      最後の段階は lexical intents と名付けられました。ここでは、ユーザが本 bot の好みや意見について質問しているのかどうかなど、ユーザの要求を分析するために正規表現を用いました。lexical intents は、トピック対話モジュール (topic dialog modules) で様々な戦略を選択するため設計されました。
    - Dialog Module Selector    
      dialog module selector は最初に topic dialog module intent classifier によって検出された topic intent によって関連のある module を選び出します。応答の一貫性を保つため、選択されたモジュールは、それが応答を生成した後にシステムに "propose_continue" という信号を提供します。"CONTINUE" と設定さている場合には、ユーザの次の発話にこのモジュールを選択します (つまりその話題を継続する)。"UNCLEAR" が設定されている場合には、他の話題が検出できない場合のみ、このモジュールを選択します。"STOP" が設定されている場合には、ユーザのそれ以上の要求を処理することができないことを意味しており、我々のシステムは次のターンにこのモジュールを選択しません。この場合には、モジュールは要求をより適切に処理できる別のモジュールを探索する必要があります。そうでなければ、本システムは提案されていない、あるいは話されていないトピックの対話モジュールを提案する特別なテンプレートを選択し、それをモジュールの返答に連結します、提案されるモジュールの優先度は、毎日更新される各モジュールのパフォーマンスに応じて変わります。本 selector はユーザが次のターンでシステムの提案を選択したと判断されたとき、それは提案されたモジュールを選択します。例えば 発話が "let's talk about movies" というものであったとき、dialog module selector は直ちに movie module を選択します。
*** Low Level Dialog Management
    - Fact and Back-story Delivery
      我々は、Backstory と EVI を、一般的な事実についての応答と chatbot 自身への応答のため、2つのAPIを用いました。
      - Backstory
        このサービスは、この bot の背景（出身）や好みに関する質問への回答を生成するために設計されたものです。例えば "what is your favorite sport" などがこれの対応対象です。我々はユーザの質問や我々の事前に作っておいた質問を埋め込むため Google の Universal Sentence Encoder を用いました。つまり、その質問文をベクトルとして類似度を取ります。それぞれのより深い質問については、 Backstory の モジュールが処理できるようにしています。（例えば"what is your favorite sport" -> <basketball> -> "why do you like basketball" -> <...>）
      - EVI
        Amazon から提供されるサービスです。これは例えば "how old is Lebron James."というような 一般的な質問を答えるために用いられます。もしEVIが正しい答えを知らない場合には、"I don't have opinion on that" ないし "I don't know about that" と答えます。また Alexa skills link を直接返してしまう可能性があるので、返ってきた内容を一旦後処理したものを回答とします。 (Alexa skills link が不明なため翻訳に疑問あり：原文 Also, since it sometimes returns Alexa skills link directly, we post-process the result instead of returning directly.)
    - Topic Dialog Modules
      それぞれの対話モジュールは独自の対話フローを持つように設計されています。ここで我々が今回設計したモジュールを一覧します。
      - Animal
        Animal モジュールは動物についての対話を設計したものです。 Reddit API や 手打ちされた情報を元に作成された様々な応答の組み合わせは、様々な動物についての雑学を生成するために使用されています。この話題については若いユーザからのアクセスが多く、この応答についてはより厳格に冒涜フィルタ (profanity filter) を通しています。このモジュールは他にも、彼らのペットやお気に入りの動物などについてのカジュアルなチャットをユーザに提供できるようになっています。
      - Movie and Book
        この2つは同じような設計をされています。TMDB API と Goodreads API をそれぞれ用いて、幅広く映画や書籍を検出することができます。また IMDB や Reddit より毎日更新される情報を元に特定の映画や書籍について対話を行うことができるようになっています。最後に事前に定義された応答を用いて意見や経験についての雑談をすることができます。(原文：Finally, they can engage in chit chat about opinions and experiences using predefined responses)
      - Music
        music モジュールは音楽に関連した会話をユーザと行うために設計されています。Spotify の 数百万のプレイリストデータセット (Spotify's million Playlist dataset) とIMDBにあるアーティストに基づいて関連コンテンツを収集しました。
      - Sport
        Sport モジュールも設計思想は music モジュールと同様です。それは階層的な会話構造を作ります。この設計に伴って、スポーツの種類について話すことや、ユーザの興味に基づいて特定のスポーツに関連した話題について議論することとを自在に行き来することができるようになりました。
      - Game
        game モジュールは人気の video game をカバーしています。これはユーザと様々なビデオゲームに関した面白さや雑学について議論したり、それらに関連した質問をすることができます。この応答の品質を確保するために、殆どの事実はオンラインコンテンツから収集し手動で選択されます。ゲーム名やジャンル、発行元、利用可能なプラットフォームなど、ゲーム関する知識の一部は、IGDBの web サイトから収集されます。
      - Psycology and Philosophy
      - Holiday
      - Travel
      - Technology and Science
      - News
      - Retrieval

      全体的には dialog flow modules は Section 4 で議論される dialog flow に従います。その他に、それzレの dialog module は異なる名前のエンティティとイベントの関係を知るため我々の knowledge base にアクセスすることがあります。
** Knowledge Base
   我々の knowledge base はトピックごとにDynamoDBテーブルに格納されている統合データベースとして構築されています。データセットは Reddit や Twitter moments, Debate opinions, IMDB, Spotify などから構成されています。それらは一致するエンティティを見つける(例えばDonald Trump と wildfires（このあたりは皮肉と思われる）)ことで knowledge graph に統合されていきます。Amazonの graph database である Naptune を用いて、エンティティと Gramlin query language との関係を構築し、それらを橋渡しします。（we leveraged Amazon's graph databse Neptune to build relationships between entities and the Gramlin query language to traverse them.）
   - Factual Content
     - Reddit
       私達は様々な subreddits から毎日イベントの大規模なコレクションを構成しています。subredditは以下の話題が含まれます。Science, Technology, Politics, UpliftingNews, News, WorldNews, BusinessNews, FinanceNews, Sports, entertainment, FashionNews, Health, MusicNews, TIL, ShowerThoughts, Travel.
     - Twitter Moments
       Gunrock における Twitter Moments は ユーザが世界の話題をリアルタイムで把握できるようにすることを目的としています。Gunrock では 映画や本、政治、音楽、有名人などについて話すことができます。
     - General Information
       映画や音楽に関する一般的な情報については、IMDB データベースの情報と、Spotify の One Million Playlist dataset を用います。
       DynamoDBを使用してこれらの結果をキャッシュしておき、API制限の超過を防ぎ応答の待ち時間を短縮します。Redisは特に、特定のモジュールが提案することができる Reddit タグのリストを検索すること、例えば aerospace engineering といったものを検索するために用いています。(Redis is particularly useful for tasks such as retrieving a list of Reddit tags a particular module can propose, i.e., aerospace engineering.)
   - Opinionated Content
     - Twitter Opinions
       Gunrock は 会話をより魅力的で面白いものにするため、Twitter Momentsを用いて、リアルタイムのイベントを披露できるようになっています。
     - Debate Opinions
       Gunrock は Universal Sentence Encoder を利用することで、立場や意見といった発言を、71,000以上のトピックと460,000以上の意見に対して照合することを試みます。もしその発言認識の信頼度が高く、その意見が一般的なものであると判断されたとき、Gunrockはそのトピックやユーザの意見について直接答えます。その意見が40~60％程度のものである物議を醸す場合には、我々はユーザに意見を求め、Gunrockがまだそれについての結論を出していないと説明します。これによりユーザ間で一般的なコンセンサスを蓄積しながら、偏った問題には取り組んでいるという姿勢を示すことができます。我々はまもなく select モジュールで A/B テストが実行されます。(原文：We will be performing A/B testing on this in select modules shortly.)
       
　我々は OpenIE を用いて knowledge graph を統合していきます。OpenIEは、プレーンテキストから入力のエンティティと出力のエンティティ間のバイナリ関係を自動的に抽出できます。これらの関係はグラフデータベースで抽象化され、エンティティ間のすべてのイベントは DynamoDB でソートされます。それぞれのイベントは VADER sentiment によって極性スコア付けされます。VADER sentiment はツイートや Reddit 投稿を処理するのに理想的です。この極性スコアは知識グラフの traversal weight として利用されます。
** Natural Language Generation (NLG)
   本システムの NLG モジュールはテンプレートベースで作られています。これは手動で割り当てられたテンプレートを選択肢、dialog manager によって knowledge base から取得された情報で特定のスロットを埋めます。template manager モジュール は同じ応答が繰り返されることを避けると共に、様々ん表現形式を持つ発話を生成することができます。また生成した応答に韻律効果を加えるために、Amazon Speech Synthesis Markup Language (SSML)を用います。
*** Template Manager
    Template Manager モジュールはシステムで使用される応答テンプレートを格納して解析できるようにします。それは本システムのいくつかの並列ダイアログフローコンポーネントからすべての応答テンプレートを集中し、応答のために重複したテンプレートが選択されないことを確実にした上で、モジュールによって指定される動的なテンプレート生成を可能にします。
    template manager の主目的の一つは、応答の重複を防ぐことにあります。これを解決するために、それぞれのテンプレートに対して複数の表現形式を持つようにし、対話中にそれらがランダムかつ重複なく選ばれるようにしました。具体的には、使用されたテンプレートを各ユーザのハッシュテーブルにハッシュとして格納しました。ハッシングには、待ち時間を減らすことのできる標準的なアルゴリズムである、MD5を用いました。応答を変えることで、本システムはより自然かつ人間的な応答ができると受け取られることができ、ユーザの要求に対してただ一つの応答しか持っていないという状況を避けることができると考えています。
    またTemplate managerはモジュールによる置換のための名前付きスロットを提供することで動的なテンプレート形成ができます。例えば、movie モジュールは映画に対する面白い話を提供しますが、これはモジュールのデータベースから引き出された事実を私達の事前定義された応答テンプレートに代入することによって行われます。別の例としては、天気についてのモジュールを挙げることができます。温度の情報を提供するためのテンプレートは予め作成されており、モジュールが特定のデータ（地域や日付）を渡した後に温度が入力されます。また template manager はテンプレートが特定のスロットを使用してテンプレート内の確認応答フレーズなどの単純なセグメントを交換することを可能にします。(The template manager also allows our templates to swap out simple segments, such as acknowledgement phrases, within the templates using specific slots.)この動的なテンプレート生成は我々の応答がバラエティに富むものにすることを助け、書く必要のあるテンプレート量を減らすことができます。
*** Prosody Synthesis
    本システムは音声合成にAmazon Alexaの音声合成システムを利用しています。私達はテンプレート強化、例えば電話番号を読み上げるとき、またはホモグラフや頭字語を正しく発音するために Amazon SSML format を用います。加えて、``whoops" や ``uh-oh" といったつなぎ言葉をマークアップとして（ex. <say-as interpret-as="interjection">Okey dokey</say-as>）追加することで、応答をより人間的にします。また意図的に長い文を分割して息継ぎの時間を開けることで、自然に聞こえるようにします。同様に冗談の前にそれらを追加することでユーザの期待を高める効果を狙います。音声の例については、Amazonの公式にある Spoeechcon のリファレンスを参照してください。
* An Example Dialog
  例は省略



  私達は意見や経験を持つことがbot を人間化するために不可欠であると信じています。
  実験により、ユーザエンゲージメントには、確認応答が重要であることがわかりました。対話は、情報交換のプロセスとみなすことができます。これは話し手と聞き手がお互いに理解できたときに成功したとみなせます。また同時にユーザとの理解の差を埋めるためにも役立つと考えられます。
  会話を長引かせるために、本システムは複雑なイニシアティブを持つように設計しました。ユーザが特定のトピックを要求したり質問したりする場合には、適切に対応するようにしています。ユーザが現在のトピックに興味が持ている場合には、本システムはより詳細に話題を掘り下げていきます。これは同時にシステム側が主導権を握ることができます。ユーザが明確な意図や実用的な要求を持っていない場合には、本システムは別のトピックを提案するか、または関連した質問をします。
* Results and Analysis
  省略
** Module Performance Analysis
   我々は各ターン固有のモジュールのパフォーマンスを評価するために、各ターン毎の平均評価を用います。ここで用いる各ターンとは、完全な対話の評価に等しく貢献するものと仮定しています（つまり重み付けをしていません）。各モジュールが評価に与える影響は、ヒットしたターンの数と相関関係があるものとできるはずなので、ダイアログあたりの平均評価よりもこの基準を選択しました。（パーツとその頻度を考慮したいという意図？）
*** Topic level analysis
    省略
    それぞれのトピックでの評価について触れている
*** Lexical analysis
    また教師なし学習とテキストマイニングを適用して、人々がどのようなエンティティについて話すのが好きなのかを分析しました。図6(論文参照)は、評価をscattertext で描画したものになります。 x 軸は単語の頻度を示し、y軸は単語と評価の関係を示します。私達は多人数のユーザがテクノロジーやゲーム、そして動物について話したがっていたものの、それらに対して低い評価しか得られなかったことを発見しました。これは「ロボット」や「約束」、「犬」といった単語に多く関連付けられているようでした。この結果を受けて私達はこれらに対応するモジュールの強化に注力しました。また「宗教」や「ゴシップ」「うんち（おそらくこれはBotを馬鹿にする意図？）」といった低評価と物議を醸してしまったトピックとの相関関係も見られました。これを受けて私達はこのような話題を回避するような設計を施しました。更に流行であったトピックに対しては高い評価が得られることもわかりました。これをうけてユーザが現在の出来事について話すことが好きなのであろうと私達は推測しています。よって私達はTwitter Moment を利用して 「Today's holiday」モジュールと「Flash news」モジュールを作成しました。結局私達はこの大規模なユーザデータを開発の決定と研究の方向性の基盤の一つとして活用しました。
    
** Dialog Strategy Effectiveness
   本システムの開発において、私達はアジャイル開発を行い、特に昨日の更新とバグ修正に力を入れました。なぜならば、この開発方式はより高い適応力を持ってchatbot の性能を向上させることができるからです。しかしながら、これは私達が行った変更点に対する対象実験をすることが難しくなってしまいました。そこでGoogleのRパッケージである「CausualImpact」を用いることで開発サイクルにおけるユーザエクスペリエンスと評価基準の変更の影響を分析しました。このパッケージによって他のテスト方法が機能のリリースサイクルと互換性がない場合でも、システムの変更による影響を見積もることができます。また実装した新しい機能についてもパイロットテストを実施しており、これらの機能を一度に一モジュールずつプッシュすることができます。これは評価の変更が機能の更新と並行して行うことができることを意味しています。
*** Acknowledgement with Knowledge Graph reasoning
    Grounding は非タスク指向の対話システムにとって効果的な対話戦略であることが知られています。さらに chatbot は知識の獲得と推論を行う必要があるため、ユーザの意図や好みを承認することにはより意味があると考えられます。それはまた滑らかで魅力的な会話を作るために信頼できるNLU、knowledge graph を持つことに依存しているので非常に挑戦的な試みであると言える。我々は知識を獲得し整理するためのより良いシステムの構造を提案したので、我々は knowledge graph を利用しながら異なるモジュールに同意を追加することを実験しました。つまり例を挙げるならば、book モジュールで、ユーザがノンフィクション本よりもフィクション本を好んでいると応答した場合、「Great, I remember reading Harry Potter and the Sorcerer's Stone from the Harry Potter series.」とchatbotは同意の（？）応答をします。
    図6(元論文参照)において、この効果を示しています。これを導入した途端順調に評価が伸びていることが理解できると思います。（詳細省略）つまりはこの同意という行為はコミュニケーションにおいて大きな効果を持っているということです。
** System Latency
   エンジニアリングは優れたユーザエクスペリエンスを保証する製品を構築する上で重要な役割を果たします。本システムは94％という高い稼働率を維持することができました。
   ユーザへの応答時にシステムの待ち時間を減らすことは評価を向上させる上で非常に有効であることがわかりました。再リリースの悪影響を避けるために、新しい機能が追加されるたびにシステムの待ち時間を監視します。一時期長い待ち時間が発生してしまうことがありましたが、AWS Lambda関数のメモリとCPU容量を増やすことでバグを解決しました。またこのレイテシを短縮することで評価が向上するかどうかの分析も行いました。
* Visualization Tool
  省略
* Conclusion
  私達は発話の検出や、対話管理、韻律を含む音声合成に多くの貢献をしました。具体的には、オープンドメインの音声言語理解を処理するための三層音声言語理解パイプラインを提案したこと、対話の文脈情報を利用して事実と意見をシームレスに切り替える柔軟な対話フローを可能にする階層的 dialog managerを設計したこと、トーン調整と休符挿入を介してより自然な応答を構築する韻律音声合成機構を作成したことを挙げられます。
* Future Work
  競争の激しさや限られた期限のため、対話行為の分類やASR修正、及び韻律合成を行うことができたものの、これらに対してより厳格な実験的分析を行うことができませんでした。今後 A/B テストを実施する予定です。更に、システムを改善したい部分はいくつか挙げることができます。例えば性別や性格、トピックに対する興味といったユーザモデリングを行うこと、それに基づいて提案されたトピックの選択を改善し、各ユーザに適応的で固有の会話経験を提供できるようにしたいと考えています。このためには、今後のイベントや様々なユーザの興味をあおるアイデアを提案できるようにより堅牢な推薦システムを構築したいと考えています。
  またサブモジュールの選択と会話内容の方針のためのより良いシステムを訓練するために強化学習を利用したいと考えています。適切なレストランや観光名所の推奨など、ユーザが特定の目的で助けを求める場合には、ソーシャル雑談対話 (social chit chat) とタスク指向の会話を組み合わせてケースをより適切に処理することを期待します。またデータ駆動型の意見応答、及びトピック討論のためのサブシステムを構築したいと考えています。これにより、人気のあるトピックについてユーザと適切かつ主体的な議論が可能になると思われます。最後にシステムがユーザとの対話データから自動的に学習できるように、特にシステムに慣れていないトピックについてもオンライン学習手法を調査したいと考えています。

