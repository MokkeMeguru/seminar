#+TITLE: Semi-supervised Text Style Transfer: Cross Projection in Latent Space

* 論文概要
** 概要
   テキストの意味を保持したスタイルの変換タスクの手法を提案して、高い成績を残した。
   スタイル A-B のテキスト群に対して f(.) g(.) の関数を一部のペアなデータセットを用いて学習、
   f(.) = g(.)^{-1} となるようにすることでスタイルの変換を行う
** 著者
   中国の大学 Wangxuan Institute of Computer Technology, Peking University
   (こういったスタイル変換の研究はアメリカは少なく、特に中国が多いイメージ。恐らく性差などが言語にあらわれるかどうかなどが影響？)
   
** 通った会議
   EMNLP 自然言語処理系統でかなり知名度が高い国際会議、らしい。技術よりなイメージ。
   日本で通っている例を挙げると、TEASPN (言語入力支援フレームワーク) などを挙げることが出来る。

** 何に注目しているか？
   潜在表現を Mapping する手法としては Cross-Aligned Style Transfer や Sequence to Better Sequence などを挙げることが出来るが、
   前者は個人的にアイデア的に打ち止めな発想だと考えており 
   後者は学習が極めて難しい。


   またマッピング自体が所謂関数＋逆関数の学習なので、
   Flow-base Model と組み合わせたら学習器が少なくて済みそう。

   （あとイントロダクションなどが読みやすく、修論の参考にしたい）

** Cross-Aligned Style Transfer 
   (Style Transfer from non-parallel text by cross alignment)
*** 概要  
   Style A と Style B の文に対して、 文 x_a, x_b 、ラベル y_a, y_b
   G([x_a, y_a]) と G([x_b, y_a]) とそれを区別する Discriminater x 2
*** where.
   G は [x_i, y_j] を初期重みとする RNN で
   D は G が文章を生成する最中＋し終わった中間表現を入力として 0/1 ラベルを付与する。
*** 問題点
   正確に潜在表現を扱っているのかよくわからない(単語並び替えは難しい)
   => Transformer(BERT) は単語並び替えは高い評価が出るらしい (NLPWeb研究室より)
   
** Abstruct
   スタイル変換タスクは、 *意味を保ちながら* あるスタイルを持つテキストを別のスタイルを持つテキストに変換するタスクを指す。
   しかしこれは大規模な並行データが存在しないことが学習・モデル作成を困難にさせていると考えている。
   この論文では、半教師あり学習（ここでは少ないペアデータと比較的に大量のペアでないデータを用いる、という意味）を提案している。さらに2種類の半教師あり学習手法を提案した。
   さらに評価を行うに際して、中国語の詩の現代語・古代語のものを作成し公開した。

** 導入
   近年、テキスト生成の分野にたいして興味を持つ研究者が増えている。テキスト生成の分野というのは具体的には応答文生成、機械翻訳、そして機械要約、更には質問生成などである。これらのタスクにおいて、困難であり注目もされている(???)タスクとして、テキストのスタイル変換というタスクがある。

   テキストのスタイル変換とは、ある特定のドメインに存在するテキストに対して、この変換システムを通すことで別のドメインのテキストを生成することを指す。ここで重要な制約として、各テキストは意味的には同値であることが挙げられる。ここでドメインの例としては、古代・現代の詩のスタイル対、肯定的・否定的な文の対というような広く曖昧なものを指す。(日本語だとここに方言や所謂性差のようなものを含めることが出来る)
   
   このようなスタイル変換を行うモデルを作成するに際して、用意できる並行なデータセットがそれを学習・評価するには少なすぎる、という問題がある。これは意味が同値であることを保証できる並行なコーパスを構築するコストが主な原因として挙げられる。また仮にこのコーパスを生成できたとしても、それは Neural Network を用いて訓練するにはデータは不足することが見込まれる。
   
   この課題に対処するために、先行研究では非並行なデータセットを用いた学習（スタイル変換の分野ではこれを教師なし学習と呼ぶ）が第一線となっている。
   
   一般的に用いられる手法としては、テキストから意味要素を抽出し、そこからスタイルを付与する、といった手法 (John et al 2018; Shen et al. 2017, Hu et al. 2017) がある。まずスタイルの表現とスタイルに依存しない意味表現を、入力または中間表現上で分離できるように生成モデルを学習し、次に意味表現と付与したいスタイルを組み合わせることでスタイルの変換されたテキストを生成する。この手法の重要な、そして難しい点は、生成モデルはスタイルの表現情報と意味表現の情報を正確に読み解ける必要があるという点だ。

   しかし Lample et al (2019) の研究によれば、この ``読み解き" は簡単なものではなく、既存の方法はスタイルに依存しない意味表現を抽出するように学習することは困難だ。

   この議論を受けて、この論文ではテキストのスタイル・意味分離に代わって、異なるスタイルについての潜在空間の間を橋渡しする Projection (投影) レイヤーを含む微分可能な Encodeer-Decoder based Model を提案する。具体的には、
   
   1. 異なるスタイルのテキストに対して Encoder はそれらを異なる潜在空間の潜在表現に写像する。
   2. あるスタイルの潜在空間を別のスタイルの潜在表現に投影する関数を導入する
   3. Decoder は潜在空間に表現された特定のサンプルを復元することでそのスタイル空間のテキストを生成する。

      

   一般的に非並行なスタイル変換に関するコーパスについては容易に手に入るものと仮定する。（中国は沢山ありますが、日本語だと…）そのデータセットを用いて小規模な並行なデータセットを構築することは不可能ではない。よってモデルを教師なし学習、教師あり学習の両方で訓練できるように2種類の目的関数を設計した。具体的には非並行データについてはそのスタイルについての潜在空間の学習を行い、並行データについては東映関数についての学習を行う。最終的にモデルはこれらの2つの目的を組み合わせた半教師あり学習として訓練される。

   評価手法としては、英語の正式な文と非正式な文とでのスタイル変換タスク、及び古代中国語の詩と現代中国語の詩のスチある変換タスクについて実験を行ったものを変換された文の Accuracy と人的アノテーションを用いて、意味の保持度合い、スタイルの精度、文の流暢さを評価するものと設定した。実験結果はこの提案手法がより評価の高い文章を生成できるものであると示している。

   簡潔に本研究が貢献した内容を列挙すると次のようになる。
   
- 半教師ありモデルの提案
- 単純な非並行データと並行データを両方活用できる効果的な2つの半教師あり手法の提案
- 中国語のスタイル変換に関するデータセットの公開

   
      

** TODO
- 2つの半教師あり手法とは何か？
  おそらく並行データセットを用いるもの、非並行データセットを用いるもの、という意味での2つの半教師あり手法だと考えられるが、英語的に正しいのか不明
