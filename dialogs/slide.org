#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+options: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+options: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+options: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+title: 迷走したので最近の対話系の研究達を眺める
#+date: <2019-04-24 Wed>
#+author: MokkeMeguru
#+email: meguru.mokke@gmail.com
#+language: ja
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 25.2.2 (Org mode 9.2.2)
* [悲報] 迷走した
  　のんびりと好き勝手に論文を読んでいたら自分の立ち位置がわからなくなってしまった。
  
  　明日どころか右も左もわからなくなったので、一旦自分がやりたそうな分野の研究分野とその現状を俯瞰して見ようと思う。
* 対話システムってなんだ                                                 :ok:
  　最近の IPhone ネイティブな人々にとって、対話システムってなんだと言われてはじめに思い浮かべるのは、Siri辺りだろうか。勿論これは正しいのだが、分野をわかりやすくするために少し分野を区切ってみよう。詳しくは  [[https://qiita.com/MeguruMokke/items/4fa85814bb465f64c52d#%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AA%E7%A0%94%E7%A9%B6%E5%88%86%E9%87%8E%E3%81%AA%E3%81%AE%E3%81%8B][対話分野の研究をしたいときに気をつけたいこと]] 辺りを参照して頂きたい。

  - タスク志向型対話システム
    　タスク志向型対話システムとは、対話によってユーザないしエージェントを特定の目標が達成できるように導くためのシステムで、例えば人狼ゲームや、店の受付に向いているシステムであると言える。
    
  - 非タスク志向型対話システム
    　非タスク志向対話システムとは、簡単に言ってしまえば雑談をするための対話システムで、Twitterなどの雑談Bot等に向いているシステムであると言える。またこのタイプの対話システムを作るコンテストとして、対話システムコンペティションというものがある。
    
  - 上2つの融合型
    　上2つの融合型とは、雑談対話を行うものの、特別な命令等(例えば消灯、点灯)が行われれば、それらが実行できる対話システムを指している。例えば、Amazon Alexaや、Gateboxなどがこちらに含まれるだろう。またこのタイプの対話システムを作るコンテストとして、Amazon Alexa Prizeというものがある。
* どんな研究があるのか
  　ぱっと3つに研究分野を区切ったが、研究分野はここから更に分化するため、物凄く多岐に渡っている。論文になるのはその一部であったりするし、逆に全く別の内容の研究がこの分野の研究に含まれていたりする。なので大凡自然言語処理、と書いてあれば大体対話系の研究分野といってもこじつけることが出来る。
  　例えばNER (Named Entity Recognition 固有表現抽出)  の技術は [[https://qiita.com/MeguruMokke/items/561e778ccd69e5160c74][Gunrock]] と呼ばれる対話システム中で出てくる、名詞句の抽出で用いられたりする。
** Amazon Alexa級の対話システムの今
   　ここでは論文として研究成果を積極的に公表している Amazon Alexa Prize の 2017年度、2018年度の最優秀システムを眺めることで、どのような研究内容があるのかを見ていこうと思う。他にも Microsoft のりんな などについても対話システムの研究内容を知るために重要であると考えられるが、こちらは論文があまり詳細に書かれていないので、割愛する。
*** 一般的なアーキテクチャ
    　まずSounding Board、Gunrockの概要図を以下に引用する。
    
    [図1][図2]
    　
    　以下の図から、入力、システム、データベースの3つがあることと、システム部に Natural  Language Understanding、Dialog Manager、Natural  Language Generation の3つがあることがわかるだろう。
    
    　
*** ここで使われている技術
    　一般的には、
        　まず入力の部分についてだが、音声認識による音声→テキスト変換を行っていること、音声合成によるテキスト→音声が行われていることがわかるだろう。これらは自然言語処理とは少し離れるかもしれないが、対話システムを構成する重要なシステムである。これらは精度もさることながら、低質な計算機(モバイル機器)でもそれなりの速度で実行できる必要があり、なおかつ精度も必要となる分野である。この分野で現状強いモデルとして挙げられるものとしては、音声合成としては2019年頭頃まででは [[https://arxiv.org/abs/1811.00002v1][WaveGlow]]  を挙げることが出来るだろう(実装も公開済み、[[https://nv-adlr.github.io/WaveGlow][合成例]])。(+音声認識については調査不足+)

        　NLUの部分については二者が異なるため、それぞれについて軽く触れる。

        　
        　
* その他読んできた論文を短く説明してみる
  　ここでは対話系の研究内容に含まれるであろう研究内容について簡単に触れてみる。
  - [[https://www.ai-gakkai.or.jp/jsai2014/webprogram/2014/pdf/752.pdf][ルールベース発話生成と統計的発話生成の融合に基づく対話システムの構築]]
    　この提案手法では、一般には対話をルールベースで作成するという方針を持っているが、そのうちで応答が不適当な物があれば、それを棄却し統計的発話生成を行う、という対話システムのエラー処理のような手法を提案している。
  - [][A Survey on Dialogue Systems: Recent Advances and New Frontiers]
  - [][Automatic Expressive Opinion Sentence Generation for Enjoyable Conversational Systems]
  - [[https://arxiv.org/pdf/1605.06069.pdf][A Hierarchical Latent Variable Encoder-Decder Model for Generating Dialogues]]
* これから取り組めそうな問題                                       :noexport:
  　現状を見る限り、データベースと機械学習の融合を行って対話システムが構成される現在の流れは後10年ほどは健在であるように思われる。よって、End-to-End な対話システムを研究していくよりは、データベースなどを組み合わせた対話システムを研究するほうが得策であると考えている。(考えればきりがないが)その前提でいくつか取り組めそうな問題について考察してみる。
 
  　まず、自然言語のデータをデータベースに入れるための前処理や手法については、既存の手法を用いていることが多く、まだ検討の余地があるように思われる。例えば自然言語→知識ベースのi橋渡しを行うOpenIEの技術などが例に挙げることが出来るだろう。
  
  　それに関連すると、ユーザからの発話からより情報を取り出す技術についてはより研究が出来ると考えられる。例えば日本語の発話には多くの場合、文脈による省略や、指示語が多く含まれる。これらを文脈を考慮してより上手く補完すれば(Context Analysis、Coreference Resolution)、対話システムの精度を向上させることが出来るだろう。
  
  　またNLGの部分にも研究の余地が残っている。対話システムの文を生成する部分では、現状テンプレートを用いた物がほとんどである(尚りんなはその限りではない)。というのも知識ベースから取り出した内容をテンプレートに押し込む、というスタイルが非常に手軽であるため、それ以外の手法が難しいためであると考えられる。これらを解く手法としては、例えばRDFデータから文生成を行う、[[https://aclweb.org/anthology/P18-1151][GTR-LSTM]] 等が考えられるが、実用で用いる例については個人的な観測範囲では存在していない。

  　更に、多くの場合で同じ入力からは同じ出力しか得られないという問題についても考える必要がある。Gunrockでは発話に多様性を持たせるために複数のテンプレートを用意する、という対処をしていたが、上手く多様性をもたせる手法について考察してみることも出来るだろう。

  　欲を言えば、対話システムに個人情報を持たせる手法も考えたい。GunrcockではBackstoryを用いて生年月日などの情報を保持し、それらを参照する必要がある際にそこから情報を取り出すという処理を行っていたが、例えばこれの影響を口調などに反映する手法については十分に面白みのある研究と思われる。また入力や出力に合わせて音声の韻律制御を考えることも面白いかもしれない。
